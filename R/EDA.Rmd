---
title: "Descriptive Stats"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

```{r}
library(readxl)
library(dplyr)
library(tidyr)
library(ggplot2)
```

# Read in and shape data  

Really should source another script or write a function to do this, but I'm in the early days.

```{r}
#### READ IN DATA ####
# working off NEveg outputs here; our template will be different
# these have cover, density, and height in the same sheet
# and an extra row at the top for which marsh zone each plant "belongs to"
# anything that does NOT have 'Canopy Ht' or 'Density' in the column name 
# once identifying info stops is percent cover
grb_in <- here::here("data", "GRB Data Packet 6-8-21.xlsx")
wqb_in <- here::here("data", "WQB Data Packet 2011-2020.xlsx")
```

## Change reserve HERE

```{r}
# work with GRB first
dat <- read_xlsx(grb_in, sheet = "Veg",
                 skip = 1)
```

```{r}
# bust up into data types, like we'll get in the template
id_cols <- dat %>% 
    select("Reserve Code":"Marsh Zone")
density <- dat %>% 
    select(contains("Density"))
height <- dat %>% 
    select(contains("Canopy Ht"))
cover <- dat %>% 
    select(-("Reserve Code":"Marsh Zone"),
           -contains("Density"),
           -contains("Canopy Ht"))

# make sure the numbers add up
ncol(dat) == ncol(id_cols) + ncol(density) + ncol(height) + ncol(cover)

# for now, just work with cover
cover <- cover %>% 
    select(-contains("Unknown"),
           -contains("Notes")) %>% 
    mutate_all(as.numeric) %>% 
    cbind(id_cols, .)

# pivot to long
cover_long <- pivot_longer(cover,
                           cols = (ncol(id_cols) + 1):ncol(cover),
                           names_to = "Species",
                           values_to = "pct_cover") %>% 
    janitor::clean_names()

# cringe to do this, but turn NAs into 0s, because if all data was entered properly,
# anything that wasn't recorded should be 0.
# will be important to check individual data points in some graphs
# to make sure there aren't any mistaken 0s.

cover_long <- cover_long %>% 
    mutate(pct_cover = case_when(is.na(pct_cover) ~ 0,
                                 TRUE ~ pct_cover))

```

# Descriptive info/metadata-ish stuff    

What do I want to know:  

+  how many sites are there?  
+  how many transects per site?  
+  how many plots per transect?  
+  date range?  
+  missing data?  

Would be good to turn this into a shiny app or something; it's going to be a LOT of output otherwise  

```{r}

```


# Exploratory analysis of vegetation data  

Here I want to know things like:  

+  what is the average percent cover by species and transect  
+  how does that look over time: showing all plots, averaging to transect, maybe averaging to station?  
+  how many species appear  
+  how many species appear a LOT (unsure how to define this for R; it's a "know it when I see it" kind of thing) - what's dominant, what's common, etc. because we can potentially narrow everything down to just a few species.  
+  NE project made pie charts for each site, each year. Could do this. Potentially also stacked bar chart or something. Unsure what would be cleanest.  
  +  probably have to combine some (several) species into an "other" category. `dplyr` has some way to do this, right? anything making up less than X% gets lumped together?    
  +  can facet a stacked bar chart by site. x = year, y = species (proportion at site), facet = site.  
  +  would a scatter/line plot work just as well? Maybe? could be easier to follow an individual species.....  
